{"cells":[{"cell_type":"code","source":["#Regresion lineal , Tema 3: Regresion\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets, linear_model\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\nnp.random.seed(1)\n\n#iris\niris = datasets.load_iris()\nX_train, X_test, Y_train, Y_test = train_test_split(iris.data[:,2:3], iris.data[:,3:4], test_size=0.3)\nregresionLineal = linear_model.LinearRegression()\nregresionLineal.fit(X_train, Y_train)\npredict = regresionLineal.predict(X_test)\nscore = regresionLineal.score(X_test,Y_test)\nerror = mean_squared_error(Y_test,predict)\nprint(\"score: %f error: %f\"%(score, error))\nplt.scatter(X_test,Y_test,  color='black')\nplt.plot(X_test, predict, color='blue', linewidth=3)\nplt.xticks(())\nplt.yticks(())\nplt.show()\n#display()\n\n#diabetes\ndiabetes = datasets.load_diabetes()\ndX_train, dX_test, dY_train, dY_test = train_test_split(diabetes.data[:,0:2], diabetes.target, test_size=0.3)\ndregresionLineal = linear_model.LinearRegression()\ndregresionLineal.fit(dX_train, dY_train)\ndpredict = dregresionLineal.predict(dX_test)\ndscore = dregresionLineal.score(dX_test,dY_test)\nderror = mean_squared_error(dY_test,dpredict)\nprint(\"score: %f error: %f\"%(dscore, derror))"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#KNN\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn import datasets\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport numpy as np\nnp.random.seed(1)\n\niris = datasets.load_iris()\nX_train, X_test, Y_train, Y_test = train_test_split(iris.data[:,2:3], iris.data[:,3:4], test_size=0.3)\nregresionLineal = linear_model.LinearRegression()\nknn = KNeighborsRegressor(10)\nknn.fit(X_train, Y_train) \npredict = knn.predict(X_test)\nscore = knn.score(X_test,Y_test)\nerror = mean_squared_error(Y_test,predict)\nprint(\"score: %f error: %f\"%(score, error))\nplt.clf()#limpia el buffer del plot\nplt.scatter(X_test,Y_test,  color='black')\nplt.scatter(X_test,predict,  color='blue')\nplt.xticks(())\nplt.yticks(())\nplt.show()\n#display()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from sklearn import datasets\nfrom sklearn.linear_model.stochastic_gradient import SGDRegressor\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(1)\n\niris = datasets.load_iris()\nX=iris.data[:,2:3]\nY=iris.data[:,3:4]\n# Crear data sets de entrenamiento y testeo\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n\nSGD = SGDRegressor()\n\n#2 Train it\nSGD.fit(X_train, Y_train)\n\n#3. Make test predictions\nest_tst = SGD.predict(X_test)\n\nMSE_tst = mean_squared_error(est_tst, Y_test)\nR2_coeff = SGD.score(X_test, Y_test)\n\nprint('MSE: ' + str(MSE_tst))\nprint('Variance score: ' + str(R2_coeff))\n\n# Plot outputs\nplt.clf() #limpia el buffer del plot\nplt.scatter(X_test, Y_test, color='black')\nplt.plot(X_test, est_tst, color='blue', linewidth=3)\n\nplt.xticks(())\nplt.yticks(())\n\nplt.show()\ndisplay()\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn import datasets,svm\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport numpy as np\nnp.random.seed(1)\n\niris = datasets.load_iris()\nX=iris.data[:,2:3]\nY=iris.data[:,3:4]\n# Crear data sets de entrenamiento y testeo\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n\n#K-nn regressor con CV\nk_max=40\nrang_k=np.arange(1,k_max+1)\ntuned_parameters = [{'n_neighbors':rang_k}]\nnfold = 5\nneigh = KNeighborsRegressor()\nneigh_CV=GridSearchCV(neigh,tuned_parameters,cv=nfold)\n\nneigh_CV.fit(X_train,Y_train)\npredict=neigh_CV.predict(X_test)\n\nK_CV=neigh_CV.best_params_['n_neighbors']\n\nerror =  mean_squared_error(Y_test,predict)\nscore=neigh_CV.score(X_test,Y_test)\n\nprint('Vecinos: '+str(K_CV))\nprint('MSE: '+str(error))\nprint('Variance score: '+str(score))\n\nplt.clf()#limpia el buffer del plot\nplt.scatter(X_test,Y_test,  color='black')\nplt.scatter(X_test,predict,  color='blue')\nplt.xticks(())\nplt.yticks(())\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"Tema3_JavierGuillamon","notebookId":4166151454329392},"nbformat":4,"nbformat_minor":0}
